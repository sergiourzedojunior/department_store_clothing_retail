{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from datetime import datetime, date\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cufflinks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcufflinks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot, iplot\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cufflinks'"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "from plotly.offline import plot, iplot\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "cf.go_offline()\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:21.963940Z",
     "iopub.status.busy": "2024-03-08T01:02:21.963940Z",
     "iopub.status.idle": "2024-03-08T01:02:23.532031Z",
     "shell.execute_reply": "2024-03-08T01:02:23.532031Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Carregar o arquivo Excel\n",
    "xls = pd.ExcelFile('Exercicio_Python_CRM .xlsx')\n",
    "\n",
    "# Obter os nomes das abas\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "# Para cada aba, ler o schema e as primeiras 10 linhas\n",
    "for sheet in sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name=sheet, nrows=10)\n",
    "    # print(f\"Schema para {sheet}:\")\n",
    "    # print(df.dtypes)\n",
    "    # print(f\"Primeiras 10 linhas para {sheet}:\")\n",
    "    # print(df.head(10))\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "# arquivo\n",
    "wb = openpyxl.load_workbook('Exercicio_Python_CRM .xlsx', read_only=True)\n",
    "\n",
    "# aba de transações\n",
    "ws = wb['Transações']\n",
    "\n",
    "# tamanho do chunk para leitura de bases grandes\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "# cabeçalho (nomes das colunas) da primeira linha\n",
    "header = [cell.value for cell in ws[1]]\n",
    "\n",
    "# dados em chunks para bases com milhões de linhas\n",
    "for i in range(2, ws.max_row, chunk_size):  # Comecça de 2 porque a primeira linha é o cabeçalho\n",
    "    rows = ws[i:i + chunk_size]\n",
    "    data = [[cell.value for cell in row] for row in rows]\n",
    "    df = pd.DataFrame(data, columns=header)  # Usando o cabeçalho como nomes das colunas\n",
    "    chunks.append(df)\n",
    "\n",
    "# Concatenando os chunks em um único DataFrame\n",
    "df_t = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Para cada coluna no DataFrame\n",
    "for col in df_t.columns:\n",
    "    # Se o tipo de dados da coluna é object (string)\n",
    "    if df_t[col].dtype == 'object':\n",
    "        # Remova os espaços em branco no início e no final\n",
    "        df_t[col] = df_t[col].str.strip()\n",
    "\n",
    "df_t['Promo'] = df_t['Promo'].astype(str)\n",
    "cols = [col for col in df_t.columns if 'ID' not in col]\n",
    "null_counts = df_t.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dbc](dbc.jpg)\n",
    "![renner](renner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da base de dados Exercicio_Python_CRM .xlsx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primeira parte da análise:\n",
    "- análise descritiva da base de Transações\n",
    "- agregação Ano e Mês\n",
    "- KPI Ticket Médio\n",
    "###### nesta primeira parte da análise é possível verificar que:\n",
    "- a base apenas possui dados para 01-2022 até 09-2022 e depois 01-2023 até 09-2023 faltando o último trimestre dos dois anos; época de Natal, black friday e dia das crianças!\n",
    "- as vendas de 2023 apenas se recuperaram no terceiro trimestre. É provável que esta recuperação continuasse no terceiro semestre indicando uma tendência de crescimento ao longo do ano, o que não acontece em 2022.\n",
    "- 2022 teve um pico em Março (semana do consumidor), mas houve um decréscimo em junho (dia dos namorados). Em 2023 parece que houve uma venda melhor relacionada ao calendário de junho.\n",
    "- o ano de 2023 teve menos promoções e menos Unidades vendidas em relação a 2022, porém obteve um Valor Total maior indicando que houve um Ticket Médio maior em 2023 em relação a 2022\n",
    "- o Ticket Médio de 2023 foi sempre maior que 2022 no agregado mês a mês\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:23.532031Z",
     "iopub.status.busy": "2024-03-08T01:02:23.532031Z",
     "iopub.status.idle": "2024-03-08T01:02:23.548763Z",
     "shell.execute_reply": "2024-03-08T01:02:23.548763Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a paleta de cores Pastel2\n",
    "pastel2 = ['#b3e2cd', '#fdcdac', '#cbd5e8', '#f4cae4', '#e6f5c9', '#fff2ae', '#f1e2cc', '#cccccc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando colunas para o mês e o ano\n",
    "df_t['Year'] = df_t['Data'].dt.year\n",
    "df_t['Month'] = df_t['Data'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupando os dados por ano e mês\n",
    "grouped = df_t.groupby(['Year', 'Month'])[['ValorTotal', 'UnidadesVendidas']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:24.065601Z",
     "iopub.status.busy": "2024-03-08T01:02:24.064601Z",
     "iopub.status.idle": "2024-03-08T01:02:24.169112Z",
     "shell.execute_reply": "2024-03-08T01:02:24.169112Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Criando a figura\n",
    "# fig = go.Figure()\n",
    "\n",
    "# # Adicionando o gráfico de barras para 'ValorTotal'\n",
    "# for i, year in enumerate(grouped['Year'].unique()):\n",
    "#     fig.add_trace(go.Bar(x=grouped[grouped['Year'] == year]['Month'], \n",
    "#                          y=grouped[grouped['Year'] == year]['ValorTotal'], \n",
    "#                          name='ValorTotal ' + str(year),\n",
    "#                          marker_color=pastel2[i % len(pastel2)]))  # Use a cor correspondente da paleta\n",
    "\n",
    "# # Adicionando o gráfico de linha para 'UnidadesVendidas'\n",
    "# for i, year in enumerate(grouped['Year'].unique()):\n",
    "#     line_color = '#ff0000' if year == 2023 else pastel2[(i + len(pastel2) // 2) % len(pastel2)]  # Use a cor vermelha para 2023\n",
    "#     fig.add_trace(go.Scatter(x=grouped[grouped['Year'] == year]['Month'], \n",
    "#                              y=grouped[grouped['Year'] == year]['UnidadesVendidas'], \n",
    "#                              name='UnidadesVendidas ' + str(year), \n",
    "#                              yaxis='y2',\n",
    "#                              line_color=line_color))\n",
    "\n",
    "# # Configurando os eixos e a legenda\n",
    "# fig.update_layout(\n",
    "#     title={\n",
    "#         'text': \"Unidades Vendidas e Valor Total por Mês e Ano\",\n",
    "#         'y':0.9,\n",
    "#         'x':0.5,\n",
    "#         'xanchor': 'center',\n",
    "#         'yanchor': 'top'}, \n",
    "#     xaxis=dict(title='Month'),\n",
    "#     yaxis=dict(title='ValorTotal'),\n",
    "#     yaxis2=dict(title='UnidadesVendidas', overlaying='y', side='right'),\n",
    "#     autosize=False,\n",
    "#     width=1200,  # Aumenta a largura da figura\n",
    "#     height=500,  # Aumenta a altura da figura\n",
    "#     legend=dict(\n",
    "#         x=1.1,  \n",
    "#         y=1,  # Posiciona a legenda no topo\n",
    "#         bgcolor='rgba(255, 255, 255, 0)',  # Fundo transparente para a legenda\n",
    "#         bordercolor='rgba(255, 255, 255, 0)'  # Borda transparente para a legenda\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# plotly.offline.plot(fig)\n",
    "\n",
    "# # Save the figure as a .png file\n",
    "# pio.write_image(fig, 'figure2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a figura\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionando o gráfico de barras para 'ValorTotal'\n",
    "for i, year in enumerate(grouped['Year'].unique()):\n",
    "    fig.add_trace(go.Bar(x=grouped[grouped['Year'] == year]['Month'], \n",
    "                         y=grouped[grouped['Year'] == year]['ValorTotal'], \n",
    "                         name='ValorTotal ' + str(year),\n",
    "                         marker_color=pastel2[i % len(pastel2)]))  # Use a cor correspondente da paleta\n",
    "\n",
    "# Adicionando o gráfico de linha para 'UnidadesVendidas'\n",
    "for i, year in enumerate(grouped['Year'].unique()):\n",
    "    line_color = '#ff0000' if year == 2023 else pastel2[(i + len(pastel2) // 2) % len(pastel2)]  # Use a cor vermelha para 2023\n",
    "    fig.add_trace(go.Scatter(x=grouped[grouped['Year'] == year]['Month'], \n",
    "                             y=grouped[grouped['Year'] == year]['UnidadesVendidas'], \n",
    "                             name='UnidadesVendidas ' + str(year), \n",
    "                             yaxis='y2',\n",
    "                             line_color=line_color))\n",
    "\n",
    "# Configurando os eixos e a legenda\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Unidades Vendidas e Valor Total por Mês e Ano\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'}, \n",
    "    xaxis=dict(title='Month'),\n",
    "    yaxis=dict(title='ValorTotal'),\n",
    "    yaxis2=dict(title='UnidadesVendidas', overlaying='y', side='right'),\n",
    "    autosize=False,\n",
    "    width=1200,  # Aumenta a largura da figura\n",
    "    height=500,  # Aumenta a altura da figura\n",
    "    legend=dict(\n",
    "        x=1.1,  \n",
    "        y=1,  # Posiciona a legenda no topo\n",
    "        bgcolor='rgba(255, 255, 255, 0)',  # Fundo transparente para a legenda\n",
    "        bordercolor='rgba(255, 255, 255, 0)'  # Borda transparente para a legenda\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#plotly.offline.iplot(fig)\n",
    "\n",
    "# Save the figure as a .png file\n",
    "# pio.write_image(fig, 'figure2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - As unidades vendidas de 2023 só crescem no terceiro semestre, assim como o valor total. O comportamento é praticamente o inverso de 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:24.177300Z",
     "iopub.status.busy": "2024-03-08T01:02:24.176795Z",
     "iopub.status.idle": "2024-03-08T01:02:24.449713Z",
     "shell.execute_reply": "2024-03-08T01:02:24.449713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preenchendo os valores nulos na coluna 'Promo' com 0\n",
    "df_t['Promo'] = df_t['Promo'].fillna(0)\n",
    "\n",
    "# Convertendo a coluna 'Promo' para float, substituindo NaNs por 0 e depois convertendo para inteiro\n",
    "df_t['Promo'] = np.nan_to_num(df_t['Promo'].astype(float)).astype(int)\n",
    "\n",
    "# Filtrando os dados para os anos de 2022 e 2023\n",
    "df_t['Year'] = df_t['Data'].dt.year\n",
    "df_t['Month'] = df_t['Data'].dt.month\n",
    "df_filtered = df_t[df_t['Year'].isin([2022, 2023])]\n",
    "\n",
    "# Criando a tabela agregada\n",
    "pivot = df_filtered.pivot_table(index='Month', columns='Year', values=['ValorTotal', 'UnidadesVendidas', 'Promo'], aggfunc='sum')\n",
    "\n",
    "# Adicionando a linha com o valor total\n",
    "pivot.loc['Total'] = pivot.sum()\n",
    "\n",
    "# Extraindo a linha 'Total'\n",
    "total_values = pivot.loc['Total']\n",
    "\n",
    "# Transpondo a série para um DataFrame e resetando o índice\n",
    "total_df = total_values.transpose().reset_index()\n",
    "\n",
    "# Renomeando as colunas\n",
    "total_df.columns = ['Category', 'Year', 'Value']\n",
    "\n",
    "# Pivotando o DataFrame\n",
    "pivot_total = total_df.pivot(index='Category', columns='Year', values='Value')\n",
    "\n",
    "# Calculando a mudança percentual\n",
    "pivot_total['Change (%)'] = (pivot_total[2023] - pivot_total[2022]) / pivot_total[2022] * 100\n",
    "\n",
    "pivot_total['Ticket Médio 2022'] = pivot_total[2022]['ValorTotal'] / pivot_total[2022]['UnidadesVendidas']\n",
    "pivot_total['Ticket Médio 2023'] = pivot_total[2023]['ValorTotal'] / pivot_total[2023]['UnidadesVendidas']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definindo o tamanho da figura\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add a title to the plot\n",
    "ax.set_title('Valores Totais e Ticket Médio por ano', fontsize=50, pad=20)\n",
    "\n",
    "# Rest of your code...\n",
    "# Adicionando a tabela à figura\n",
    "table_data = pivot_total.reset_index().round(2).values.tolist()\n",
    "column_labels = pivot_total.reset_index().columns.tolist()\n",
    "\n",
    "# Definindo as cores\n",
    "colors = sns.color_palette(\"Pastel2\").as_hex()\n",
    "\n",
    "# Criando uma matriz de cores\n",
    "cell_colors = [[colors[i%len(colors)] for _ in row] for i, row in enumerate(table_data)]\n",
    "\n",
    "# Adicionando a tabela à figura\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc = 'center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Ajustando o tamanho da fonte\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(30)  # Increase this value to increase the font size\n",
    "\n",
    "# Aumentando a largura e altura geral da tabela\n",
    "table.scale(4, 4)  # Increase the second value to increase the height of the rows\n",
    "\n",
    "# Ajustando o tamanho da fonte dos cabeçalhos\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(30)  # Increase this value to increase the font size of the headers\n",
    "\n",
    "# Ajustando o tamanho da fonte da coluna 'DescProduto'\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] == 0:  # 0 é o índice da coluna 'DescProduto'\n",
    "        cell.set_fontsize(30)  # Increase this value to increase the font size of the 'DescProduto' column\n",
    "# Escondendo os eixos\n",
    "ax.axis('off')\n",
    "\n",
    "plt.show()\n",
    "# Salvando a figura como .png\n",
    "#plt.savefig('pivot_total_table.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### \n",
    "###### - praticamente metade das promoções em 2023 em relação a 2022\n",
    "###### - queda nas unidades vendidas de 1,5% em 2023 em relação a 2022\n",
    "###### - Aumento de faturamento - Valor Total de 10,82% em 2023 em relação a 2022\n",
    "###### - Aumento do Ticket Médio em 2023 em relação a 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:24.449713Z",
     "iopub.status.busy": "2024-03-08T01:02:24.449713Z",
     "iopub.status.idle": "2024-03-08T01:02:25.182798Z",
     "shell.execute_reply": "2024-03-08T01:02:25.184169Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'Ticket Médio' para 2022 and 2023\n",
    "pivot[('Ticket Médio', 2022)] = pivot[('ValorTotal', 2022)] / pivot[('UnidadesVendidas', 2022)]\n",
    "pivot[('Ticket Médio', 2023)] = pivot[('ValorTotal', 2023)] / pivot[('UnidadesVendidas', 2023)]\n",
    "\n",
    "\n",
    "# Definindo o tamanho da figura\n",
    "fig, ax = plt.subplots(figsize=(20, 15))  # Aumentando a largura da figura\n",
    "\n",
    "# Add a title to the plot\n",
    "ax.set_title('Valores Totais e Ticket Médio por ano e mês', fontsize=50, pad=20)\n",
    "\n",
    "# Adicionando a tabela à figura\n",
    "table_data = pivot.reset_index().round(2).values.tolist()  # Arredondando os valores para 2 casas decimais\n",
    "column_labels = pivot.reset_index().columns.tolist()\n",
    "\n",
    "# Definindo as cores\n",
    "colors = sns.color_palette(\"Pastel2\").as_hex()\n",
    "\n",
    "# Criando uma matriz de cores\n",
    "cell_colors = [[colors[i%len(colors)] for _ in row] for i, row in enumerate(table_data)]\n",
    "\n",
    "# Adicionando a tabela à figura\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc = 'center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Ajustando o tamanho da fonte\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(30)\n",
    "\n",
    "# Ajustando o tamanho da fonte dos cabeçalhos\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(30)\n",
    "\n",
    "# Ajustando a largura das colunas e a altura das linhas\n",
    "table.scale(4.5, 4)  # Aumentando a largura das colunas e a altura das linhas\n",
    "\n",
    "# Escondendo os eixos\n",
    "ax.axis('off')\n",
    "\n",
    "# Salvando a figura como .png\n",
    "plt.savefig('pivot_table_with_ticket_medio.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - destaque Ticket Médio maior em todos os meses de 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:25.184169Z",
     "iopub.status.busy": "2024-03-08T01:02:25.184169Z",
     "iopub.status.idle": "2024-03-08T01:02:25.446330Z",
     "shell.execute_reply": "2024-03-08T01:02:25.446330Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Define a list of colors\n",
    "colors = ['#b3e2cd', '#fdcdac', '#cbd5e8', '#f4cae4', '#e6f5c9', '#fff2ae', '#f1e2cc', '#cccccc']\n",
    "\n",
    "# Calcular o Ticket Médio\n",
    "df_t['Ticket Médio'] = df_t['ValorTotal'] / df_t['UnidadesVendidas']\n",
    "\n",
    "# Agrupar os dados e calcular a média\n",
    "df_grouped = df_t.groupby(['Year', 'Month']).agg({'UnidadesVendidas': 'sum', 'ValorTotal': 'sum', 'Promo': 'sum', 'Ticket Médio': 'mean'}).reset_index()\n",
    "\n",
    "# Obter o número de colunas\n",
    "num_cols = len(df_grouped.columns) - 2  # Subtrair as colunas 'Year' e 'Month'\n",
    "\n",
    "# Calcular o número de linhas e colunas para os subplots\n",
    "num_rows = num_cols // 2 if num_cols % 2 == 0 else num_cols // 2 + 1\n",
    "\n",
    "# Criar subplots\n",
    "fig = make_subplots(rows=num_rows, cols=2, subplot_titles=df_grouped.columns[2:])\n",
    "\n",
    "# Adicionar traços\n",
    "for i, header in enumerate(df_grouped.columns[2:]):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    for j, year in enumerate(df_grouped['Year'].unique()):\n",
    "        df_year = df_grouped[df_grouped['Year'] == year]\n",
    "        fig.add_trace(go.Scatter(x=df_year['Month'], y=df_year[header], mode='lines', name=f'{header} {year}', line=dict(color=colors[j % len(colors)])), row=row, col=col)\n",
    "\n",
    "# Atualizar layout\n",
    "fig.update_layout(height=600, width=800, title_text=\"Subplots\")\n",
    "fig.show()\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - movimentos atípicos de volume de vendas em 2022 em Março e em 2023 em junho e setembro\n",
    "###### - Ticket Médio é outro destaque em 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda parte da análise:\n",
    "- explorando os dados de transações com as Marcas e suas categorias\n",
    "\n",
    "##### nesta segunda parte da análise é possível verificar que:\n",
    "\n",
    "###### O top vermelho gammaz - teve ótimo desempenho,\n",
    "###### - ficou em segundo lugar no rank de Ticket Médio (TM) no ano de 2023. Caiu 1 posição em relação a 2022\n",
    "###### - se manteve em primeiro em relação a Unidades Vendidas e Valor Total (VT) 2022 e 2023\n",
    "###### - fez menos promoções em 2023 em relação a 2022 - caiu de sexto em quantidade de promoções para sétimo\n",
    "###### mas o Botton azul Gammaz também teve destaque!\n",
    "\n",
    "###### 2023\tBottom Azul Marca GammaZ  ->\tTM - 88.517723\t VT - 75759.52\n",
    "###### 2023\tTop Vermelho Marca GammaZ ->\tTM - 83.774699\t VT - 146329.22\n",
    "\n",
    "###### O Botton azul gammaz que não foi vendido em 2022 teve um desempenho melhor em 2023 quando se olha pra Ticket Médio.\n",
    "\n",
    "###### A Marca Gammaz no geral teve um bom desempenho pra Ticket Médio e Valor Total, ultrapassando em Valor Total a Marca AlfaX\n",
    " \n",
    "###### As promoções não impulsionaram o negócio de forma geral\n",
    "\n",
    "###### Cores vermelhas são representativas em vendas, mas um destaque foram peças azuis, que melhoraram tanto em quantidade vendida, quanto em aumento de ticket médio e valor Total\n",
    "\n",
    "###### Houve crescimento de Ticket médio de peças tipo Botton e também Valor Total, o que ajuda a explicar o sucesso do Botton azul gammaz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:25.453330Z",
     "iopub.status.busy": "2024-03-08T01:02:25.453330Z",
     "iopub.status.idle": "2024-03-08T01:02:25.484525Z",
     "shell.execute_reply": "2024-03-08T01:02:25.484525Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# arquivo\n",
    "wb = openpyxl.load_workbook('Exercicio_Python_CRM .xlsx', read_only=True)\n",
    "\n",
    "# aba de produto\n",
    "ws = wb['Produto']\n",
    "\n",
    "# tamanho do chunk para leitura de bases grandes\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "# cabeçalho (nomes das colunas) da primeira linha\n",
    "header = [cell.value for cell in ws[1]]\n",
    "\n",
    "# dados em chunks para bases com milhões de linhas\n",
    "for i in range(2, ws.max_row, chunk_size):  # Comecça de 2 porque a primeira linha é o cabeçalho\n",
    "    rows = ws[i:i + chunk_size]\n",
    "    data = [[cell.value for cell in row] for row in rows]\n",
    "    df = pd.DataFrame(data, columns=header)  # Usando o cabeçalho como nomes das colunas\n",
    "    chunks.append(df)\n",
    "\n",
    "# Concatenando os chunks em um único DataFrame\n",
    "df_p = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Para cada coluna no DataFrame\n",
    "for col in df_p.columns:\n",
    "    # Se o tipo de dados da coluna é object (string)\n",
    "    if df_p[col].dtype == 'object':\n",
    "        # Remova os espaços em branco no início e no final  \n",
    "        df_p[col] = df_p[col].str.strip()\n",
    "\n",
    "\n",
    "# Ajuste da coluna 'Descrição Produto'\n",
    "def update_description(row):\n",
    "    if row['Categoria'] not in row['Descrição Produto']:\n",
    "        row['Descrição Produto'] = row['Categoria'] + ' ' + row['Descrição Produto']\n",
    "    if row['Cor'] not in row['Descrição Produto']:\n",
    "        row['Descrição Produto'] = row['Descrição Produto'].replace(row['Categoria'], row['Categoria'] + ' ' + row['Cor'])\n",
    "    if 'Marca' not in row['Descrição Produto'] and row['Marca'] not in row['Descrição Produto']:\n",
    "        row['Descrição Produto'] = row['Descrição Produto'].replace(row['Marca'], 'Marca ' + row['Marca'])\n",
    "    return row\n",
    "\n",
    "df_p = df_p.apply(update_description, axis=1)\n",
    "\n",
    "df_p.loc[df_p['ID_Produto'] == 123010, 'Descrição Produto'] = 'Bottom Azul Marca GammaZ'\n",
    "df_p.loc[df_p['ID_Produto'] == 123011, 'Descrição Produto'] = 'Bottom Azul Marca BetaY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:25.501102Z",
     "iopub.status.busy": "2024-03-08T01:02:25.501102Z",
     "iopub.status.idle": "2024-03-08T01:02:26.285110Z",
     "shell.execute_reply": "2024-03-08T01:02:26.285110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ajuste da coluna 'Descrição Produto'\n",
    "def update_description(row):\n",
    "    if row['Categoria'] not in row['Descrição Produto']:\n",
    "        row['Descrição Produto'] = row['Categoria'] + ' ' + row['Descrição Produto']\n",
    "    if row['Cor'] not in row['Descrição Produto']:\n",
    "        row['Descrição Produto'] = row['Descrição Produto'].replace(row['Categoria'], row['Categoria'] + ' ' + row['Cor'])\n",
    "    if 'Marca' not in row['Descrição Produto'] and row['Marca'] not in row['Descrição Produto']:\n",
    "        row['Descrição Produto'] = row['Descrição Produto'].replace(row['Marca'], 'Marca ' + row['Marca'])\n",
    "    return row\n",
    "\n",
    "df_p = df_p.apply(update_description, axis=1)\n",
    "df_p.loc[df_p['ID_Produto'] == 123010, 'Descrição Produto'] = 'Bottom Azul Marca GammaZ'\n",
    "df_p.loc[df_p['ID_Produto'] == 123011, 'Descrição Produto'] = 'Bottom Azul Marca BetaY'\n",
    "df_tp = pd.merge(df_t, df_p, on='ID_Produto', how='left')\n",
    "del df_t\n",
    "df_tp_drp = df_tp.drop(columns=['ID_Trans', 'Data', 'ID_Loja', 'ID_Produto', 'ID_Cliente', 'Month'])\n",
    "grouped_df = df_tp_drp.groupby(['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Year']).agg({'Ticket Médio': 'mean', 'UnidadesVendidas': 'sum', 'ValorTotal': 'sum', 'Promo': 'sum'}).reset_index()\n",
    "\n",
    "# Filtrar o DataFrame por ano e criar dois DataFrames separados\n",
    "df1 = grouped_df[grouped_df['Year'] == 2022].copy()\n",
    "df2 = grouped_df[grouped_df['Year'] == 2023].copy()\n",
    "\n",
    "# Criar uma classificação de \"UnidadesVendidas\" em cada DataFrame\n",
    "df1['Rank_2022_UnidadesVendidas'] = df1['UnidadesVendidas'].rank(ascending=False)\n",
    "df2['Rank_2023_UnidadesVendidas'] = df2['UnidadesVendidas'].rank(ascending=False)\n",
    "\n",
    "# Mesclar os dois DataFrames usando uma junção externa completa, trazendo apenas as colunas de classificação\n",
    "rank_UnidadesVendidas = pd.merge(df1[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2022_UnidadesVendidas']], \n",
    "                                 df2[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2023_UnidadesVendidas']], \n",
    "                                 on=['Descrição Produto', 'Categoria', 'Cor', 'Marca'], \n",
    "                                 how='outer')\n",
    "\n",
    "# Classificar o DataFrame por 'Rank_2023_UnidadesVendidas'\n",
    "rank_UnidadesVendidas = rank_UnidadesVendidas.sort_values('Rank_2023_UnidadesVendidas')\n",
    "\n",
    "# Filtrar o DataFrame por ano e criar dois DataFrames separados\n",
    "df1 = grouped_df[grouped_df['Year'] == 2022].copy()\n",
    "df2 = grouped_df[grouped_df['Year'] == 2023].copy()\n",
    "\n",
    "# Criar uma classificação de \"ValorTotal\" em cada DataFrame\n",
    "df1['Rank_2022_ValorTotal'] = df1['ValorTotal'].rank(ascending=False)\n",
    "df2['Rank_2023_ValorTotal'] = df2['ValorTotal'].rank(ascending=False)\n",
    "\n",
    "# Mesclar os dois DataFrames usando uma junção externa completa, trazendo apenas as colunas de classificação\n",
    "rank_ValorTotal = pd.merge(df1[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2022_ValorTotal']], \n",
    "                           df2[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2023_ValorTotal']], \n",
    "                           on=['Descrição Produto', 'Categoria', 'Cor', 'Marca'], \n",
    "                           how='outer')\n",
    "\n",
    "# Classifique o DataFrame por \"Rank_2023_ValorTotal\n",
    "rank_ValorTotal = rank_ValorTotal.sort_values('Rank_2023_ValorTotal')\n",
    "\n",
    "# Filtrar o DataFrame por ano e criar dois DataFrames separados\n",
    "df1 = grouped_df[grouped_df['Year'] == 2022].copy()\n",
    "df2 = grouped_df[grouped_df['Year'] == 2023].copy()\n",
    "\n",
    "# Criar uma classificação de \"Promo\" em cada DataFrame\n",
    "df1['Rank_2022_Promo'] = df1['Promo'].rank(ascending=False)\n",
    "df2['Rank_2023_Promo'] = df2['Promo'].rank(ascending=False)\n",
    "\n",
    "# Mesclar os dois DataFrames usando uma junção externa completa, trazendo apenas as colunas de classificação\n",
    "rank_Promo = pd.merge(df1[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2022_Promo']], \n",
    "                      df2[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2023_Promo']], \n",
    "                      on=['Descrição Produto', 'Categoria', 'Cor', 'Marca'], \n",
    "                      how='outer')\n",
    "\n",
    "# Classifique o DataFrame por 'Rank_2023_Promo'\n",
    "rank_Promo = rank_Promo.sort_values('Rank_2023_Promo')\n",
    "\n",
    "# Filtrar o DataFrame por ano e criar dois DataFrames separados\n",
    "df1 = grouped_df[grouped_df['Year'] == 2022].copy()\n",
    "df2 = grouped_df[grouped_df['Year'] == 2023].copy()\n",
    "\n",
    "# Criar uma classificação de \"Ticket Médio\" em cada DataFrame\n",
    "df1['Rank_2022_Ticket_Medio'] = df1['Ticket Médio'].rank(ascending=False)\n",
    "df2['Rank_2023_Ticket_Medio'] = df2['Ticket Médio'].rank(ascending=False)\n",
    "\n",
    "# Mesclar os dois DataFrames usando uma junção externa completa, trazendo apenas as colunas de classificação\n",
    "rank_Ticket_Medio = pd.merge(df1[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2022_Ticket_Medio']], \n",
    "                             df2[['Descrição Produto', 'Categoria', 'Cor', 'Marca', 'Rank_2023_Ticket_Medio']], \n",
    "                             on=['Descrição Produto', 'Categoria', 'Cor', 'Marca'], \n",
    "                             how='outer')\n",
    "\n",
    "# Classifique o DataFrame por 'Rank_2023_Ticket_Medio'\n",
    "rank_Ticket_Medio = rank_Ticket_Medio.sort_values('Rank_2023_Ticket_Medio')\n",
    "\n",
    "# Eliminar as colunas \"Categoria\" e \"Marca\n",
    "rank_UnidadesVendidas = rank_UnidadesVendidas.drop(['Categoria', 'Marca','Cor'], axis=1)\n",
    "rank_ValorTotal = rank_ValorTotal.drop(['Categoria', 'Marca','Cor'], axis=1)\n",
    "rank_Promo = rank_Promo.drop(['Categoria', 'Marca','Cor'], axis=1)\n",
    "rank_Ticket_Medio = rank_Ticket_Medio.drop(['Categoria', 'Marca','Cor'], axis=1)\n",
    "\n",
    "# Merge\n",
    "merged_df = rank_UnidadesVendidas.merge(rank_ValorTotal, how='outer', on=['Descrição Produto'])\n",
    "merged_df = merged_df.merge(rank_Promo, how='outer', on=['Descrição Produto'])\n",
    "merged_df = merged_df.merge(rank_Ticket_Medio, how='outer', on=['Descrição Produto'])\n",
    "\n",
    "# Ordenar por 'Rank_2023_Ticket_Medio'\n",
    "merged_df = merged_df.sort_values(by='Rank_2023_Ticket_Medio')\n",
    "\n",
    "cols = ['Descrição Produto', 'Rank_2022_Ticket_Medio', 'Rank_2023_Ticket_Medio'] + [col for col in merged_df.columns if col not in ['Descrição Produto', 'Rank_2022_Ticket_Medio', 'Rank_2023_Ticket_Medio']]\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "# Definir um dicionário para os nomes das novas colunas\n",
    "new_column_names = {\n",
    "    'Rank_2022_Ticket_Medio': 'Rank_22_TM',\n",
    "    'Rank_2023_Ticket_Medio': 'Rank_23_TM',\n",
    "    'Rank_2022_UnidadesVendidas': 'Rank_22_UV',\n",
    "    'Rank_2023_UnidadesVendidas': 'Rank_23_UV',\n",
    "    'Rank_2022_ValorTotal': 'Rank_22_VT',\n",
    "    'Rank_2023_ValorTotal': 'Rank_23_VT',\n",
    "    'Rank_2022_Promo': 'Rank_22_Pro',\n",
    "    'Rank_2023_Promo': 'Rank_23_Pro',\n",
    "    'Descrição Produto': 'DescProduto'\n",
    "}\n",
    "\n",
    "# Renomear as colunas\n",
    "merged_df.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Definindo o tamanho da figura\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "# Add a title to the plot\n",
    "ax.set_title('Rank por ano - Descrição de Produtos', fontsize=50, pad=20)\n",
    "\n",
    "# Adicionando a tabela à figura\n",
    "# Reset the index and drop the old index\n",
    "table_data = merged_df.reset_index(drop=True).round(2).values.tolist()\n",
    "column_labels = merged_df.reset_index(drop=True).columns.tolist()\n",
    "\n",
    "\n",
    "# Definindo as cores\n",
    "colors = sns.color_palette(\"Pastel2\").as_hex()\n",
    "\n",
    "# Criando uma matriz de cores\n",
    "cell_colors = [[colors[i%len(colors)] for _ in row] for i, row in enumerate(table_data)]\n",
    "\n",
    "# Adicionando a tabela à figura\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc = 'center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Ajustando o tamanho da fonte\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(30)\n",
    "\n",
    "# Aumentando a largura e altura geral da tabela\n",
    "table.scale(4.5, 4)  # Aumente o primeiro valor para aumentar a largura, e o segundo valor para aumentar a altura\n",
    "\n",
    "# Aumentando o tamanho da fonte\n",
    "table.set_fontsize(30)\n",
    "\n",
    "# Ajustando o tamanho da fonte dos cabeçalhos\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(30)\n",
    "\n",
    "# Ajustando o tamanho da fonte da coluna 'DescProduto'\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] == 0:  # 0 é o índice da coluna 'DescProduto'\n",
    "        cell.set_fontsize(30)  # Aumente este valor para tornar o texto maior\n",
    "# Escondendo os eixos\n",
    "ax.axis('off')\n",
    "\n",
    "# Salvando a figura como .png\n",
    "plt.savefig('merged_df_table.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - top 3 são destaques em Ticket Médio e Faturamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.285110Z",
     "iopub.status.busy": "2024-03-08T01:02:26.285110Z",
     "iopub.status.idle": "2024-03-08T01:02:26.301265Z",
     "shell.execute_reply": "2024-03-08T01:02:26.302270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criar DataFrame com colunas que contenham \"2022\"\n",
    "df_2022 = merged_df.filter(regex='DesProduto|2022')\n",
    "# Criar DataFrame com colunas que contenham \"2023\"\n",
    "df_2023 = merged_df.filter(regex='DesProduto|2023')\n",
    "# Agrupa por \"Ano\" e \"Marca\" e calcule a soma do \"ValorTotal\" e a média do \"Ticket Médio\".\n",
    "df_Marca = df_tp.groupby(['Year', 'Marca']).agg({'ValorTotal': 'sum', 'Ticket Médio': 'mean'}).reset_index()\n",
    "# Agrupa por \"Ano\" e \"Marca\" e calcule a soma do \"ValorTotal\" e a média do \"Ticket Médio\".\n",
    "df_Marca_ = df_tp.groupby(['Year', 'Marca']).agg({'Promo': 'sum', 'UnidadesVendidas': 'sum'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.304243Z",
     "iopub.status.busy": "2024-03-08T01:02:26.304243Z",
     "iopub.status.idle": "2024-03-08T01:02:26.397351Z",
     "shell.execute_reply": "2024-03-08T01:02:26.397865Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Crie um subplot com 1 linha e 2 colunas, com títulos para espaçamento\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "# Defina cores para cada ano\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "# Obtenha os anos únicos\n",
    "years = df_Marca['Year'].unique()\n",
    "\n",
    "# Para cada ano\n",
    "for i, year in enumerate(years):\n",
    "    # Filtra o DataFrame para o ano atual\n",
    "    df_year = df_Marca[df_Marca['Year'] == year]\n",
    "\n",
    "    # Crie um gráfico de barras para 'Ticket Médio'\n",
    "    fig.add_trace(go.Bar(x=df_year['Marca'], y=df_year['Ticket Médio'], name='Ticket Médio ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "\n",
    "    # Crie um gráfico de barras para 'ValorTotal'\n",
    "    fig.add_trace(go.Bar(x=df_year['Marca'], y=df_year['ValorTotal'], name='ValorTotal ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "# Atualize as propriedades do eixo x e y\n",
    "fig.update_xaxes(title_text=\"Marca\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Marca\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Ticket Médio\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"ValorTotal\", row=1, col=2)\n",
    "\n",
    "# Atualize o layout para agrupar barras em vez de empilhar, aumentar a largura da figura e ajustar o espaçamento do subplot\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "\n",
    "# Mostre a figura\n",
    "fig.show()\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - GammaZ ultrapassa AlfaX em faturamento em 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.403012Z",
     "iopub.status.busy": "2024-03-08T01:02:26.403012Z",
     "iopub.status.idle": "2024-03-08T01:02:26.490611Z",
     "shell.execute_reply": "2024-03-08T01:02:26.490611Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "\n",
    "years = df_Marca_['Year'].unique()\n",
    "\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    \n",
    "    df_year = df_Marca_[df_Marca_['Year'] == year]\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=df_year['Marca'], y=df_year['Promo'], name='Promo ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=df_year['Marca'], y=df_year['UnidadesVendidas'], name='UnidadesVendidas ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "\n",
    "fig.update_xaxes(title_text=\"Marca\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Marca\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Promo\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"UnidadesVendidas\", row=1, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - GammaZ ultrapassa AlfaX em vendas em 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.496610Z",
     "iopub.status.busy": "2024-03-08T01:02:26.496610Z",
     "iopub.status.idle": "2024-03-08T01:02:26.585684Z",
     "shell.execute_reply": "2024-03-08T01:02:26.585684Z"
    }
   },
   "outputs": [],
   "source": [
    "df_Cor = df_tp.groupby(['Year', 'Cor']).agg({'ValorTotal': 'sum', 'Ticket Médio': 'mean'}).reset_index()\n",
    "\n",
    "df_Cor_ = df_tp.groupby(['Year', 'Cor']).agg({'Promo': 'sum', 'UnidadesVendidas': 'sum'}).reset_index()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "\n",
    "years = df_Cor['Year'].unique()\n",
    "\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    \n",
    "    df_year = df_Cor[df_Cor['Year'] == year]\n",
    "\n",
    "   \n",
    "    fig.add_trace(go.Bar(x=df_year['Cor'], y=df_year['Ticket Médio'], name='Ticket Médio ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=df_year['Cor'], y=df_year['ValorTotal'], name='ValorTotal ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "\n",
    "fig.update_xaxes(title_text=\"Cor\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Cor\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Ticket Médio\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"ValorTotal\", row=1, col=2)\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - vermelho é sempre destaque\n",
    "###### - Azul tem desempenho muito forte em 2023, se recuperando em faturamento, mas principalemnte em Ticket Médio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.590681Z",
     "iopub.status.busy": "2024-03-08T01:02:26.590681Z",
     "iopub.status.idle": "2024-03-08T01:02:26.679682Z",
     "shell.execute_reply": "2024-03-08T01:02:26.679682Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "years = df_Cor_['Year'].unique()\n",
    "\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    \n",
    "    df_year = df_Cor_[df_Cor_['Year'] == year]\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=df_year['Cor'], y=df_year['Promo'], name='Promo ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=df_year['Cor'], y=df_year['UnidadesVendidas'], name='UnidadesVendidas ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Cor\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Cor\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Promo\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"UnidadesVendidas\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "\n",
    "fig.show()\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure7.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - vermelho é sempre destaque em vendas\n",
    "###### - Azul tem promoções em 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.685682Z",
     "iopub.status.busy": "2024-03-08T01:02:26.684681Z",
     "iopub.status.idle": "2024-03-08T01:02:26.764698Z",
     "shell.execute_reply": "2024-03-08T01:02:26.764698Z"
    }
   },
   "outputs": [],
   "source": [
    "df_Categoria = df_tp.groupby(['Year', 'Categoria']).agg({'ValorTotal': 'sum', 'Ticket Médio': 'mean'}).reset_index()\n",
    "\n",
    "df_Categoria_ = df_tp.groupby(['Year', 'Categoria']).agg({'Promo': 'sum', 'UnidadesVendidas': 'sum'}).reset_index()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "years = df_Categoria['Year'].unique()\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    df_year = df_Categoria[df_Categoria['Year'] == year]\n",
    "\n",
    "    fig.add_trace(go.Bar(x=df_year['Categoria'], y=df_year['Ticket Médio'], name='Ticket Médio ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=df_year['Categoria'], y=df_year['ValorTotal'], name='ValorTotal ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Categoria\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Categoria\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Ticket Médio\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"ValorTotal\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "fig.show()\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure8.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - Top fatura mais, mas Bottom melhora Ticket médio em 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.769699Z",
     "iopub.status.busy": "2024-03-08T01:02:26.769699Z",
     "iopub.status.idle": "2024-03-08T01:02:26.844699Z",
     "shell.execute_reply": "2024-03-08T01:02:26.844699Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "years = df_Categoria_['Year'].unique()\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    df_year = df_Categoria_[df_Categoria_['Year'] == year]\n",
    "\n",
    "    fig.add_trace(go.Bar(x=df_year['Categoria'], y=df_year['Promo'], name='Promo ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=df_year['Categoria'], y=df_year['UnidadesVendidas'], name='UnidadesVendidas ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Categoria\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Categoria\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Promo\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"UnidadesVendidas\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "fig.show()\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.847697Z",
     "iopub.status.busy": "2024-03-08T01:02:26.847697Z",
     "iopub.status.idle": "2024-03-08T01:02:26.860698Z",
     "shell.execute_reply": "2024-03-08T01:02:26.860698Z"
    }
   },
   "outputs": [],
   "source": [
    "df_Descrição_Produto = df_tp.groupby(['Year', 'Descrição Produto']).agg({'ValorTotal': 'sum', 'Ticket Médio': 'mean'}).reset_index()\n",
    "df_Descrição_Produto_ = df_tp.groupby(['Year', 'Descrição Produto']).agg({'Promo': 'sum', 'UnidadesVendidas': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.865698Z",
     "iopub.status.busy": "2024-03-08T01:02:26.865698Z",
     "iopub.status.idle": "2024-03-08T01:02:26.988297Z",
     "shell.execute_reply": "2024-03-08T01:02:26.988297Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "years = df_Descrição_Produto['Year'].unique()\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    df_year = df_Descrição_Produto[df_Descrição_Produto['Year'] == year]\n",
    "\n",
    "    fig.add_trace(go.Bar(x=df_year['Descrição Produto'], y=df_year['Ticket Médio'], name='Ticket Médio ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Bar(x=df_year['Descrição Produto'], y=df_year['ValorTotal'], name='ValorTotal ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Descrição Produto\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Descrição Produto\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Ticket Médio\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"ValorTotal\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure10.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - Ticket Médio e faturamento - destaques Top Vermelho e Bottom Azul GammaZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:26.993297Z",
     "iopub.status.busy": "2024-03-08T01:02:26.993297Z",
     "iopub.status.idle": "2024-03-08T01:02:27.113674Z",
     "shell.execute_reply": "2024-03-08T01:02:27.113674Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"\",\"\"))\n",
    "\n",
    "colors = {'2022': ['rgb(179,226,205)', 'rgb(253,205,172)'], '2023': ['rgb(102,194,165)', 'rgb(252,141,98)']}\n",
    "\n",
    "years = df_Descrição_Produto_['Year'].unique()\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    df_year = df_Descrição_Produto_[df_Descrição_Produto_['Year'] == year]\n",
    "\n",
    "    fig.add_trace(go.Bar(x=df_year['Descrição Produto'], y=df_year['Promo'], name='Promo ' + str(year), marker_color=colors[str(year)][0]), row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=df_year['Descrição Produto'], y=df_year['UnidadesVendidas'], name='UnidadesVendidas ' + str(year), marker_color=colors[str(year)][1]), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Descrição Produto\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Descrição Produto\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Promo\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"UnidadesVendidas\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(barmode='group', width=1200, margin=dict(b=100))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure11.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:27.122673Z",
     "iopub.status.busy": "2024-03-08T01:02:27.115672Z",
     "iopub.status.idle": "2024-03-08T01:02:27.249536Z",
     "shell.execute_reply": "2024-03-08T01:02:27.249536Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_plot_for_brand(brand):\n",
    "    # Obter produtos e anos exclusivos para a marca\n",
    "    products = df_tp[df_tp['Marca'] == brand]['Descrição Produto'].unique()\n",
    "    years = sorted(df_tp[df_tp['Marca'] == brand]['Year'].unique())\n",
    "\n",
    "    # color sequence\n",
    "    colors = ['#66c2a5','#fc8d62','#8da0cb','#e78ac3','#a6d854','#ffd92f']\n",
    "\n",
    "    # dicionário para mapear anos a cores\n",
    "    year_color = {year: colors[i % len(colors)] for i, year in enumerate(years)}\n",
    "\n",
    "    # dicionários para armazenar a média de \"Ticket Médio\" e somar \"UnidadesVendidas\", \"ValorTotal\" e \"Promo\" para cada produto e ano\n",
    "    ticket_medio_means = {year: {} for year in years}\n",
    "    unidades_vendidas_sums = {year: {} for year in years}\n",
    "    valor_total_sums = {year: {} for year in years}\n",
    "    promo_sums = {year: {} for year in years}\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for year in years:\n",
    "        for product in products:\n",
    "            # Filtrar DataFrame por produto e ano\n",
    "            df_product_year = df_tp[(df_tp['Marca'] == brand) & (df_tp['Descrição Produto'] == product) & (df_tp['Year'] == year)]\n",
    "\n",
    "            # média de \"Ticket Médio\" e a soma de \"UnidadesVendidas\", \"ValorTotal\" e \"Promo\".\n",
    "            ticket_medio_mean = df_product_year['Ticket Médio'].mean()\n",
    "            unidades_vendidas_sum = df_product_year['UnidadesVendidas'].sum()\n",
    "            valor_total_sum = df_product_year['ValorTotal'].sum()\n",
    "            promo_sum = df_product_year['Promo'].sum()\n",
    "\n",
    "            # Armazena esses valores nos dicionários\n",
    "            ticket_medio_means[year][product] = ticket_medio_mean\n",
    "            unidades_vendidas_sums[year][product] = unidades_vendidas_sum\n",
    "            valor_total_sums[year][product] = valor_total_sum\n",
    "            promo_sums[year][product] = promo_sum\n",
    "\n",
    "        # Adicionar uma barra ou linha ao gráfico, dependendo do ano\n",
    "        if year == 2022:\n",
    "            fig.add_trace(go.Bar(x=products, y=[ticket_medio_means[year][product] for product in products], name=f'{year}', marker_color=year_color[year],\n",
    "                                 hovertemplate='Ticket Médio: %{y:.2f}<br>Unidades Vendidas: %{customdata[0]:.2f}<br>Valor Total: %{customdata[1]:.2f}<br>Promo: %{customdata[2]:.2f}<extra></extra>',\n",
    "                                 customdata=[[unidades_vendidas_sums[year][product], valor_total_sums[year][product], promo_sums[year][product]] for product in products]))\n",
    "        elif year == 2023:\n",
    "            # Calcule a variação percentual de 2022 a 2023 para cada produto\n",
    "            percent_variations = [(ticket_medio_means[year][product] / ticket_medio_means[2022][product] - 1) * 100 for product in products]\n",
    "\n",
    "            fig.add_trace(go.Scatter(x=products, y=[ticket_medio_means[year][product] for product in products], mode='lines', name=f'{year}', line=dict(color=year_color[year]),\n",
    "                                     hovertemplate='Ticket Médio: %{y:.2f}<br>Variation from 2022: %{customdata[0]:.2f}%<br>Unidades Vendidas: %{customdata[1]:.2f}<br>Valor Total: %{customdata[2]:.2f}<br>Promo: %{customdata[3]:.2f}<extra></extra>',\n",
    "                                     customdata=[[percent_variations[i], unidades_vendidas_sums[year][product], valor_total_sums[year][product], promo_sums[year][product]] for i, product in enumerate(products)]))\n",
    "\n",
    "    # layout\n",
    "    fig.update_layout(\n",
    "        height=600, \n",
    "        width=900, \n",
    "        title_text=f\"Ticket Médio for {brand}\", \n",
    "        xaxis_title=\"Descrição Produto\", \n",
    "        yaxis_title=\"Ticket Médio\", \n",
    "        barmode='group',\n",
    "        xaxis_tickangle=-90\n",
    "    )\n",
    "\n",
    "  \n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "\n",
    "brands = df_tp['Marca'].unique()\n",
    "\n",
    "for brand in brands:\n",
    "    create_plot_for_brand(brand)\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure12.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:28.286933Z",
     "iopub.status.busy": "2024-03-08T01:02:28.286933Z",
     "iopub.status.idle": "2024-03-08T01:02:28.303377Z",
     "shell.execute_reply": "2024-03-08T01:02:28.303377Z"
    }
   },
   "outputs": [],
   "source": [
    "# liberando espaço na memória\n",
    "# Get a dictionary of all variables in your current namespace\n",
    "variables = locals()\n",
    "\n",
    "# Convert the items to a list before iterating\n",
    "for var_name, var_value in list(variables.items()):\n",
    "    if isinstance(var_value, pd.DataFrame) and var_name != 'df_tp':\n",
    "        del variables[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Terceira parte da análise:\n",
    "- Clientes e Lojas\n",
    "\n",
    "###### nesta terceira parte da análise é possível verificar que:\n",
    "\n",
    "- As lojas 5 (SP), 8 (RS) e 2 (MG) foram as que melhor performaram em relação a Ticket Médio no ano de 2023\n",
    "- Para estas lojas a Classe B é a com maior Ticket Médio no ano de 2023 e o sexo feminino se destaca neste quesito\n",
    "- nas faixas etárias há um diferença entre as lojas quando se trata de Ticket Médio no ano de 2023\n",
    "- - loja 5 -> 18-25\n",
    "- - loja 8 -> 25-35\n",
    "- - loja 2 -> 45+\n",
    "- as tabelas trazem detalhes que podem auxiliar em decisões futuras de MKT de froma mais detalhada\n",
    "- A primeira loja da tabela é a primeira do Rank (ordenado por Ticket Médio 2023); e assim por diante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:28.306338Z",
     "iopub.status.busy": "2024-03-08T01:02:28.306338Z",
     "iopub.status.idle": "2024-03-08T01:02:28.336978Z",
     "shell.execute_reply": "2024-03-08T01:02:28.336978Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# arquivo\n",
    "wb = openpyxl.load_workbook('Exercicio_Python_CRM .xlsx', read_only=True)\n",
    "\n",
    "# aba de Cliente\n",
    "ws = wb['Cliente']\n",
    "\n",
    "# tamanho do chunk para leitura de bases grandes\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "# cabeçalho (nomes das colunas) da primeira linha\n",
    "header = [cell.value for cell in ws[1]]\n",
    "\n",
    "# dados em chunks para bases com milhões de linhas\n",
    "for i in range(2, ws.max_row, chunk_size):  # Comecça de 2 porque a primeira linha é o cabeçalho\n",
    "    rows = ws[i:i + chunk_size]\n",
    "    data = [[cell.value for cell in row] for row in rows]\n",
    "    df = pd.DataFrame(data, columns=header)  # Usando o cabeçalho como nomes das colunas\n",
    "    chunks.append(df)\n",
    "\n",
    "# Concatenando os chunks em um único DataFrame\n",
    "df_c = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Para cada coluna no DataFrame\n",
    "for col in df_c.columns:\n",
    "    # Se o tipo de dados da coluna é object (string)\n",
    "    if pd.api.types.is_object_dtype(df_c[col]):\n",
    "        # Remova os espaços em branco no início e no final\n",
    "        df_c[col] = df_c[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:28.336978Z",
     "iopub.status.busy": "2024-03-08T01:02:28.336978Z",
     "iopub.status.idle": "2024-03-08T01:02:28.370300Z",
     "shell.execute_reply": "2024-03-08T01:02:28.370300Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# arquivo\n",
    "wb = openpyxl.load_workbook('Exercicio_Python_CRM .xlsx', read_only=True)\n",
    "\n",
    "# aba de Cliente\n",
    "ws = wb['Lojas']\n",
    "\n",
    "# tamanho do chunk para leitura de bases grandes\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "# cabeçalho (nomes das colunas) da primeira linha\n",
    "header = [cell.value for cell in ws[1]]\n",
    "\n",
    "# dados em chunks para bases com milhões de linhas\n",
    "for i in range(2, ws.max_row, chunk_size):  # Comecça de 2 porque a primeira linha é o cabeçalho\n",
    "    rows = ws[i:i + chunk_size]\n",
    "    data = [[cell.value for cell in row] for row in rows]\n",
    "    df = pd.DataFrame(data, columns=header)  # Usando o cabeçalho como nomes das colunas\n",
    "    chunks.append(df)\n",
    "\n",
    "# Concatenando os chunks em um único DataFrame\n",
    "df_l = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Para cada coluna no DataFrame\n",
    "for col in df_l.columns:\n",
    "    # Se o tipo de dados da coluna é object (string)\n",
    "    if pd.api.types.is_object_dtype(df_l[col]):\n",
    "        # Remova os espaços em branco no início e no final\n",
    "        df_l[col] = df_l[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:28.370300Z",
     "iopub.status.busy": "2024-03-08T01:02:28.370300Z",
     "iopub.status.idle": "2024-03-08T01:02:28.387071Z",
     "shell.execute_reply": "2024-03-08T01:02:28.387071Z"
    }
   },
   "outputs": [],
   "source": [
    "# If 'Regiao' is None and 'UF' is 'SP', set 'Regiao' to 'SUDESTE'\n",
    "df_l.loc[(df_l['Regiao'].isnull()) & (df_l['UF'] == 'SP'), 'Regiao'] = 'SUDESTE'\n",
    "# If 'Regiao' is None and 'UF' is 'BH', set 'Regiao' to 'SUDESTE'\n",
    "df_l.loc[(df_l['Regiao'].isnull()) & (df_l['UF'] == 'BH'), 'Regiao'] = 'SUDESTE'\n",
    "df_merged = df_tp.merge(df_l, on='ID_Loja', how='left')\n",
    "df_final = df_merged.merge(df_c, left_on='ID_Cliente', right_on='CustomerID', how='left')\n",
    "\n",
    "# liberando espaço na memória\n",
    "# Get a dictionary of all variables in your current namespace\n",
    "variables = locals()\n",
    "\n",
    "# Convert the items to a list before iterating\n",
    "for var_name, var_value in list(variables.items()):\n",
    "    if isinstance(var_value, pd.DataFrame) and var_name != 'df_final':\n",
    "        del variables[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticket Médio por ID_Loja e Ano - a barra em vermelho indica a Loja 5 com melhor Ticket Médio agregado no ano 2023 (agregado de todos os produtos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:28.387071Z",
     "iopub.status.busy": "2024-03-08T01:02:28.387071Z",
     "iopub.status.idle": "2024-03-08T01:02:28.450005Z",
     "shell.execute_reply": "2024-03-08T01:02:28.450005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by 'ID_Loja' and 'Year' and calculate the mean of 'Ticket Médio', 'ValorTotal', and 'UnidadesVendidas'\n",
    "df_grouped = df_final.groupby(['ID_Loja', 'Year']).agg({'Ticket Médio': 'mean', 'ValorTotal': 'sum', 'UnidadesVendidas': 'sum'})\n",
    "\n",
    "# Rank 'ID_Loja' by 'Ticket Médio', 'ValorTotal', and 'UnidadesVendidas' for each year\n",
    "df_grouped['Rank_Ticket_Medio'] = df_grouped.groupby('Year')['Ticket Médio'].rank(ascending=False)\n",
    "df_grouped['Rank_ValorTotal'] = df_grouped.groupby('Year')['ValorTotal'].rank(ascending=False)\n",
    "df_grouped['Rank_UnidadesVendidas'] = df_grouped.groupby('Year')['UnidadesVendidas'].rank(ascending=False)\n",
    "# Sort df_grouped by 'ID_Loja', 'Year' and 'Rank_Ticket_Medio'\n",
    "df_sorted = df_grouped.sort_values(by=['ID_Loja', 'Rank_Ticket_Medio', 'Year'])\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Reset the index\n",
    "df_sorted_reset = df_sorted.reset_index()\n",
    "\n",
    "# Create a color sequence similar to 'Pastel2'\n",
    "color_sequence = ['#b3e2cd', '#fdcdac', '#cbd5e8', '#f4cae4', '#e6f5c9', '#fff2ae']\n",
    "\n",
    "# Get the 'ID_Loja' with the best rank in 2023\n",
    "best_rank_id_loja_2023 = df_sorted_reset[(df_sorted_reset['Year'] == 2023) & (df_sorted_reset['Rank_Ticket_Medio'] == df_sorted_reset['Rank_Ticket_Medio'].min())]['ID_Loja'].values[0]\n",
    "\n",
    "# Create a bar plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, year in enumerate(df_sorted_reset['Year'].unique()):\n",
    "    df_year = df_sorted_reset[df_sorted_reset['Year'] == year]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df_year['ID_Loja'],\n",
    "        y=df_year['Ticket Médio'],\n",
    "        name=str(year),\n",
    "        text=df_year['Rank_Ticket_Medio'],\n",
    "        legendgroup=str(year),\n",
    "        marker_color=[color_sequence[i % len(color_sequence)] if id_loja != best_rank_id_loja_2023 or year != 2023 else '#ff0000' for id_loja in df_year['ID_Loja']],  # Highlight the best rank in 2023\n",
    "        hovertemplate='ID_Loja: %{x}<br>Ticket Médio: %{y}<br>Year: '+str(year)+'<br>Rank: %{text}<extra></extra>',\n",
    "    ))\n",
    "\n",
    "# Add title and set barmode to 'group'\n",
    "fig.update_layout(title_text='Ticket Médio por ID_Loja e Ano', barmode='group')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Save the figure as a .png file\n",
    "pio.write_image(fig, 'figure14.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:28.454004Z",
     "iopub.status.busy": "2024-03-08T01:02:28.453003Z",
     "iopub.status.idle": "2024-03-08T01:02:28.466004Z",
     "shell.execute_reply": "2024-03-08T01:02:28.466004Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_unique = df_final.groupby(['ID_Loja', 'Year','Marca']).agg({'Ticket Médio': 'mean',\n",
    "    'UnidadesVendidas': 'sum',\n",
    "    'ValorTotal': 'sum'})\n",
    "df_pivot = df_grouped_unique.reset_index().pivot_table(index=['ID_Loja', 'Marca'], columns='Year', values=['Ticket Médio', 'UnidadesVendidas', 'ValorTotal'])\n",
    "\n",
    "\n",
    "df_sorted_2023 = df_sorted.loc[(slice(None), 2023), ['Rank_Ticket_Medio']]\n",
    "df_sorted_2023_sorted = df_sorted_2023.sort_values(by='Rank_Ticket_Medio')\n",
    "id_loja_list = df_sorted_2023_sorted.index.get_level_values('ID_Loja').tolist()\n",
    "\n",
    "\n",
    "df_pivot_reindexed = df_pivot.reindex(id_loja_list, level='ID_Loja')\n",
    "#df_pivot_reindexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja e Marca - Rank por Ticket médio 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Define the colors\n",
    "cmap = cm.get_cmap('Pastel2')  # Get the 'Pastel2' colormap\n",
    "colors = [cmap(i) for i in range(cmap.N)]  # Generate colors from the colormap\n",
    "\n",
    "\n",
    "# Calculate the variation for each column\n",
    "for col in ['Ticket Médio', 'ValorTotal', 'UnidadesVendidas']:\n",
    "    df_pivot_reindexed[(col, 'Variação 2022-2023')] = ((df_pivot_reindexed[(col, 2023)] - df_pivot_reindexed[(col, 2022)]) / df_pivot_reindexed[(col, 2022)]) * 100\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_pivot_reindexed = df_pivot_reindexed.fillna(0)\n",
    "\n",
    "# Reindex the columns\n",
    "df_pivot_reindexed = df_pivot_reindexed.reindex([\n",
    "    ('Ticket Médio', 2022),\n",
    "    ('Ticket Médio', 2023),\n",
    "    ('Ticket Médio', 'Variação 2022-2023'),\n",
    "    ('UnidadesVendidas', 2022),\n",
    "    ('UnidadesVendidas', 2023),\n",
    "    ('UnidadesVendidas', 'Variação 2022-2023'),\n",
    "    ('ValorTotal', 2022),\n",
    "    ('ValorTotal', 2023),\n",
    "    ('ValorTotal', 'Variação 2022-2023')\n",
    "], axis=1)\n",
    "\n",
    "# Define the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add the table to the figure\n",
    "table_data = df_pivot_reindexed.reset_index().round(2).values.tolist()\n",
    "column_labels = df_pivot_reindexed.reset_index().columns.tolist()\n",
    "\n",
    "# Create a color dictionary for each 'ID_Loja'\n",
    "id_loja_colors = {id_loja: colors[i % len(colors)] for i, id_loja in enumerate(df_pivot_reindexed.index.get_level_values('ID_Loja').unique())}\n",
    "\n",
    "# Create a color matrix based on 'ID_Loja'\n",
    "cell_colors = [[id_loja_colors[row[0]] for _ in row] for row in table_data]\n",
    "\n",
    "# Highlight the largest numbers in each column, skipping the first two columns\n",
    "for i in range(2, len(table_data[0])):\n",
    "    column_data = [row[i] for row in table_data]\n",
    "    max_value = max(column_data)\n",
    "    for j in range(len(table_data)):\n",
    "        if table_data[j][i] == max_value:\n",
    "            cell_colors[j][i] = 'red'  # Change 'red' to any color you want\n",
    "\n",
    "# Add the table to the figure\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc='center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Adjust the font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(16)\n",
    "\n",
    "# Increase the overall width and height of the table\n",
    "table.scale(5, 4.5)\n",
    "\n",
    "# Increase the font size\n",
    "table.set_fontsize(25)\n",
    "\n",
    "# Adjust the font size of the headers\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(20)\n",
    "\n",
    "# Adjust the font size of 'ID_Loja' and 'Marca' columns\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] in [0, 1]:\n",
    "        cell.set_fontsize(18)\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure as .png\n",
    "plt.savefig('df_pivot_reindexed_table.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja e UF - Rank por Ticket médio 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:30.422417Z",
     "iopub.status.busy": "2024-03-08T01:02:30.422417Z",
     "iopub.status.idle": "2024-03-08T01:02:31.172863Z",
     "shell.execute_reply": "2024-03-08T01:02:31.173208Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_unique = df_final.groupby(['ID_Loja', 'Year','UF']).agg({'Ticket Médio': 'mean',\n",
    "    'UnidadesVendidas': 'sum',\n",
    "    'ValorTotal': 'sum'})\n",
    "df_pivot = df_grouped_unique.reset_index().pivot_table(index=['ID_Loja', 'UF'], columns='Year', values=['Ticket Médio', 'UnidadesVendidas', 'ValorTotal'])\n",
    "\n",
    "\n",
    "df_sorted_2023 = df_sorted.loc[(slice(None), 2023), ['Rank_Ticket_Medio']]\n",
    "df_sorted_2023_sorted = df_sorted_2023.sort_values(by='Rank_Ticket_Medio')\n",
    "id_loja_list = df_sorted_2023_sorted.index.get_level_values('ID_Loja').tolist()\n",
    "\n",
    "\n",
    "df_pivot_reindexed = df_pivot.reindex(id_loja_list, level='ID_Loja')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the variation for each column\n",
    "for col in ['Ticket Médio', 'ValorTotal', 'UnidadesVendidas']:\n",
    "    df_pivot_reindexed[(col, 'Variação 2022-2023')] = ((df_pivot_reindexed[(col, 2023)] - df_pivot_reindexed[(col, 2022)]) / df_pivot_reindexed[(col, 2022)]) * 100\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_pivot_reindexed = df_pivot_reindexed.fillna(0)\n",
    "\n",
    "# Reindex the columns\n",
    "df_pivot_reindexed = df_pivot_reindexed.reindex([\n",
    "    ('Ticket Médio', 2022),\n",
    "    ('Ticket Médio', 2023),\n",
    "    ('Ticket Médio', 'Variação 2022-2023'),\n",
    "    ('UnidadesVendidas', 2022),\n",
    "    ('UnidadesVendidas', 2023),\n",
    "    ('UnidadesVendidas', 'Variação 2022-2023'),\n",
    "    ('ValorTotal', 2022),\n",
    "    ('ValorTotal', 2023),\n",
    "    ('ValorTotal', 'Variação 2022-2023')\n",
    "], axis=1)\n",
    "\n",
    "# Define the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add the table to the figure\n",
    "table_data = df_pivot_reindexed.reset_index().round(2).values.tolist()\n",
    "column_labels = df_pivot_reindexed.reset_index().columns.tolist()\n",
    "\n",
    "# Create a color dictionary for each 'ID_Loja'\n",
    "id_loja_colors = {id_loja: colors[i % len(colors)] for i, id_loja in enumerate(df_pivot_reindexed.index.get_level_values('ID_Loja').unique())}\n",
    "\n",
    "# Create a color matrix based on 'ID_Loja'\n",
    "cell_colors = [[id_loja_colors[row[0]] for _ in row] for row in table_data]\n",
    "\n",
    "# Highlight the largest numbers in each column, skipping the first two columns\n",
    "for i in range(2, len(table_data[0])):\n",
    "    column_data = [row[i] for row in table_data]\n",
    "    max_value = max(column_data)\n",
    "    for j in range(len(table_data)):\n",
    "        if table_data[j][i] == max_value:\n",
    "            cell_colors[j][i] = 'red'  # Change 'red' to any color you want\n",
    "\n",
    "# Add the table to the figure\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc='center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Adjust the font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(16)\n",
    "\n",
    "# Increase the overall width and height of the table\n",
    "table.scale(5, 4.5)\n",
    "\n",
    "# Increase the font size\n",
    "table.set_fontsize(25)\n",
    "\n",
    "# Adjust the font size of the headers\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(20)\n",
    "\n",
    "# Adjust the font size of 'ID_Loja' and 'UF' columns\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] in [0, 1]:\n",
    "        cell.set_fontsize(18)\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure as .png\n",
    "plt.savefig('df_pivot_reindexed_table.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja e Classe Social - Rank por Ticket médio 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:31.173208Z",
     "iopub.status.busy": "2024-03-08T01:02:31.173208Z",
     "iopub.status.idle": "2024-03-08T01:02:34.159588Z",
     "shell.execute_reply": "2024-03-08T01:02:34.159588Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_unique = df_final.groupby(['ID_Loja', 'Year','ClasseSocial']).agg({'Ticket Médio': 'mean',\n",
    "    'UnidadesVendidas': 'sum',\n",
    "    'ValorTotal': 'sum'})\n",
    "df_pivot = df_grouped_unique.reset_index().pivot_table(index=['ID_Loja', 'ClasseSocial'], columns='Year', values=['Ticket Médio', 'UnidadesVendidas', 'ValorTotal'])\n",
    "\n",
    "\n",
    "df_sorted_2023 = df_sorted.loc[(slice(None), 2023), ['Rank_Ticket_Medio']]\n",
    "df_sorted_2023_sorted = df_sorted_2023.sort_values(by='Rank_Ticket_Medio')\n",
    "id_loja_list = df_sorted_2023_sorted.index.get_level_values('ID_Loja').tolist()\n",
    "\n",
    "\n",
    "df_pivot_reindexed = df_pivot.reindex(id_loja_list, level='ID_Loja')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the variation for each column\n",
    "for col in ['Ticket Médio', 'ValorTotal', 'UnidadesVendidas']:\n",
    "    df_pivot_reindexed[(col, 'Variação 2022-2023')] = ((df_pivot_reindexed[(col, 2023)] - df_pivot_reindexed[(col, 2022)]) / df_pivot_reindexed[(col, 2022)]) * 100\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_pivot_reindexed = df_pivot_reindexed.fillna(0)\n",
    "\n",
    "# Reindex the columns\n",
    "df_pivot_reindexed = df_pivot_reindexed.reindex([\n",
    "    ('Ticket Médio', 2022),\n",
    "    ('Ticket Médio', 2023),\n",
    "    ('Ticket Médio', 'Variação 2022-2023'),\n",
    "    ('UnidadesVendidas', 2022),\n",
    "    ('UnidadesVendidas', 2023),\n",
    "    ('UnidadesVendidas', 'Variação 2022-2023'),\n",
    "    ('ValorTotal', 2022),\n",
    "    ('ValorTotal', 2023),\n",
    "    ('ValorTotal', 'Variação 2022-2023')\n",
    "], axis=1)\n",
    "\n",
    "# Define the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add the table to the figure\n",
    "table_data = df_pivot_reindexed.reset_index().round(2).values.tolist()\n",
    "column_labels = df_pivot_reindexed.reset_index().columns.tolist()\n",
    "\n",
    "# Create a color dictionary for each 'ID_Loja'\n",
    "id_loja_colors = {id_loja: colors[i % len(colors)] for i, id_loja in enumerate(df_pivot_reindexed.index.get_level_values('ID_Loja').unique())}\n",
    "\n",
    "# Create a color matrix based on 'ID_Loja'\n",
    "cell_colors = [[id_loja_colors[row[0]] for _ in row] for row in table_data]\n",
    "\n",
    "# Highlight the largest numbers in each column, skipping the first two columns\n",
    "for i in range(2, len(table_data[0])):\n",
    "    column_data = [row[i] for row in table_data]\n",
    "    max_value = max(column_data)\n",
    "    for j in range(len(table_data)):\n",
    "        if table_data[j][i] == max_value:\n",
    "            cell_colors[j][i] = 'red'  # Change 'red' to any color you want\n",
    "\n",
    "# Add the table to the figure\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc='center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Adjust the font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(16)\n",
    "\n",
    "# Increase the overall width and height of the table\n",
    "table.scale(5, 4.5)\n",
    "\n",
    "# Increase the font size\n",
    "table.set_fontsize(25)\n",
    "\n",
    "# Adjust the font size of the headers\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(20)\n",
    "\n",
    "# Adjust the font size of 'ID_Loja' and 'ClasseSocial' columns\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] in [0, 1]:\n",
    "        cell.set_fontsize(18)\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure as .png\n",
    "plt.savefig('df_pivot_reindexed_table.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja e Genero - Rank por Ticket médio 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:34.159588Z",
     "iopub.status.busy": "2024-03-08T01:02:34.159588Z",
     "iopub.status.idle": "2024-03-08T01:02:35.510757Z",
     "shell.execute_reply": "2024-03-08T01:02:35.510757Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_unique = df_final.groupby(['ID_Loja', 'Year','Genero']).agg({'Ticket Médio': 'mean',\n",
    "    'UnidadesVendidas': 'sum',\n",
    "    'ValorTotal': 'sum'})\n",
    "df_pivot = df_grouped_unique.reset_index().pivot_table(index=['ID_Loja', 'Genero'], columns='Year', values=['Ticket Médio', 'UnidadesVendidas', 'ValorTotal'])\n",
    "\n",
    "\n",
    "df_sorted_2023 = df_sorted.loc[(slice(None), 2023), ['Rank_Ticket_Medio']]\n",
    "df_sorted_2023_sorted = df_sorted_2023.sort_values(by='Rank_Ticket_Medio')\n",
    "id_loja_list = df_sorted_2023_sorted.index.get_level_values('ID_Loja').tolist()\n",
    "\n",
    "\n",
    "df_pivot_reindexed = df_pivot.reindex(id_loja_list, level='ID_Loja')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the variation for each column\n",
    "for col in ['Ticket Médio', 'ValorTotal', 'UnidadesVendidas']:\n",
    "    df_pivot_reindexed[(col, 'Variação 2022-2023')] = ((df_pivot_reindexed[(col, 2023)] - df_pivot_reindexed[(col, 2022)]) / df_pivot_reindexed[(col, 2022)]) * 100\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_pivot_reindexed = df_pivot_reindexed.fillna(0)\n",
    "\n",
    "# Reindex the columns\n",
    "df_pivot_reindexed = df_pivot_reindexed.reindex([\n",
    "    ('Ticket Médio', 2022),\n",
    "    ('Ticket Médio', 2023),\n",
    "    ('Ticket Médio', 'Variação 2022-2023'),\n",
    "    ('UnidadesVendidas', 2022),\n",
    "    ('UnidadesVendidas', 2023),\n",
    "    ('UnidadesVendidas', 'Variação 2022-2023'),\n",
    "    ('ValorTotal', 2022),\n",
    "    ('ValorTotal', 2023),\n",
    "    ('ValorTotal', 'Variação 2022-2023')\n",
    "], axis=1)\n",
    "\n",
    "# Define the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add the table to the figure\n",
    "table_data = df_pivot_reindexed.reset_index().round(2).values.tolist()\n",
    "column_labels = df_pivot_reindexed.reset_index().columns.tolist()\n",
    "\n",
    "# Create a color dictionary for each 'ID_Loja'\n",
    "id_loja_colors = {id_loja: colors[i % len(colors)] for i, id_loja in enumerate(df_pivot_reindexed.index.get_level_values('ID_Loja').unique())}\n",
    "\n",
    "# Create a color matrix based on 'ID_Loja'\n",
    "cell_colors = [[id_loja_colors[row[0]] for _ in row] for row in table_data]\n",
    "\n",
    "# Highlight the largest numbers in each column, skipping the first two columns\n",
    "for i in range(2, len(table_data[0])):\n",
    "    column_data = [row[i] for row in table_data]\n",
    "    max_value = max(column_data)\n",
    "    for j in range(len(table_data)):\n",
    "        if table_data[j][i] == max_value:\n",
    "            cell_colors[j][i] = 'red'  # Change 'red' to any color you want\n",
    "\n",
    "# Add the table to the figure\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc='center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Adjust the font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(16)\n",
    "\n",
    "# Increase the overall width and height of the table\n",
    "table.scale(5, 4.5)\n",
    "\n",
    "# Increase the font size\n",
    "table.set_fontsize(25)\n",
    "\n",
    "# Adjust the font size of the headers\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(20)\n",
    "\n",
    "# Adjust the font size of 'ID_Loja' and 'Genero' columns\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] in [0, 1]:\n",
    "        cell.set_fontsize(18)\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure as .png\n",
    "plt.savefig('df_pivot_reindexed_table.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loja e Faixa de Idade - Rank por Ticket médio 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:35.519782Z",
     "iopub.status.busy": "2024-03-08T01:02:35.518781Z",
     "iopub.status.idle": "2024-03-08T01:02:37.980078Z",
     "shell.execute_reply": "2024-03-08T01:02:37.980078Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped_unique = df_final.groupby(['ID_Loja', 'Year','FaixaIdade']).agg({'Ticket Médio': 'mean',\n",
    "    'UnidadesVendidas': 'sum',\n",
    "    'ValorTotal': 'sum'})\n",
    "df_pivot = df_grouped_unique.reset_index().pivot_table(index=['ID_Loja', 'FaixaIdade'], columns='Year', values=['Ticket Médio', 'UnidadesVendidas', 'ValorTotal'])\n",
    "\n",
    "\n",
    "df_sorted_2023 = df_sorted.loc[(slice(None), 2023), ['Rank_Ticket_Medio']]\n",
    "df_sorted_2023_sorted = df_sorted_2023.sort_values(by='Rank_Ticket_Medio')\n",
    "id_loja_list = df_sorted_2023_sorted.index.get_level_values('ID_Loja').tolist()\n",
    "\n",
    "\n",
    "df_pivot_reindexed = df_pivot.reindex(id_loja_list, level='ID_Loja')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the variation for each column\n",
    "for col in ['Ticket Médio', 'ValorTotal', 'UnidadesVendidas']:\n",
    "    df_pivot_reindexed[(col, 'Variação 2022-2023')] = ((df_pivot_reindexed[(col, 2023)] - df_pivot_reindexed[(col, 2022)]) / df_pivot_reindexed[(col, 2022)]) * 100\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_pivot_reindexed = df_pivot_reindexed.fillna(0)\n",
    "\n",
    "# Reindex the columns\n",
    "df_pivot_reindexed = df_pivot_reindexed.reindex([\n",
    "    ('Ticket Médio', 2022),\n",
    "    ('Ticket Médio', 2023),\n",
    "    ('Ticket Médio', 'Variação 2022-2023'),\n",
    "    ('UnidadesVendidas', 2022),\n",
    "    ('UnidadesVendidas', 2023),\n",
    "    ('UnidadesVendidas', 'Variação 2022-2023'),\n",
    "    ('ValorTotal', 2022),\n",
    "    ('ValorTotal', 2023),\n",
    "    ('ValorTotal', 'Variação 2022-2023')\n",
    "], axis=1)\n",
    "\n",
    "# Define the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add the table to the figure\n",
    "table_data = df_pivot_reindexed.reset_index().round(2).values.tolist()\n",
    "column_labels = df_pivot_reindexed.reset_index().columns.tolist()\n",
    "\n",
    "# Create a color dictionary for each 'ID_Loja'\n",
    "id_loja_colors = {id_loja: colors[i % len(colors)] for i, id_loja in enumerate(df_pivot_reindexed.index.get_level_values('ID_Loja').unique())}\n",
    "\n",
    "# Create a color matrix based on 'ID_Loja'\n",
    "cell_colors = [[id_loja_colors[row[0]] for _ in row] for row in table_data]\n",
    "\n",
    "# Highlight the largest numbers in each column, skipping the first two columns\n",
    "for i in range(2, len(table_data[0])):\n",
    "    column_data = [row[i] for row in table_data]\n",
    "    max_value = max(column_data)\n",
    "    for j in range(len(table_data)):\n",
    "        if table_data[j][i] == max_value:\n",
    "            cell_colors[j][i] = 'red'  # Change 'red' to any color you want\n",
    "\n",
    "# Add the table to the figure\n",
    "table = ax.table(cellText=table_data, colLabels=column_labels, cellLoc='center', loc='center', cellColours=cell_colors)\n",
    "\n",
    "# Adjust the font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(16)\n",
    "\n",
    "# Increase the overall width and height of the table\n",
    "table.scale(5, 4.5)\n",
    "\n",
    "# Increase the font size\n",
    "table.set_fontsize(25)\n",
    "\n",
    "# Adjust the font size of the headers\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[0] == 0:\n",
    "        cell.set_fontsize(20)\n",
    "\n",
    "# Adjust the font size of 'ID_Loja' and 'FaixaIdade' columns\n",
    "for key, cell in table.get_celld().items():\n",
    "    if key[1] in [0, 1]:\n",
    "        cell.set_fontsize(18)\n",
    "\n",
    "# Hide the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the figure as .png\n",
    "plt.savefig('df_pivot_reindexed_table.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:37.980078Z",
     "iopub.status.busy": "2024-03-08T01:02:37.980078Z",
     "iopub.status.idle": "2024-03-08T01:02:37.996773Z",
     "shell.execute_reply": "2024-03-08T01:02:37.996773Z"
    }
   },
   "outputs": [],
   "source": [
    "# liberando espaço na memória\n",
    "# Get a dictionary of all variables in your current namespace\n",
    "variables = locals()\n",
    "\n",
    "# Convert the items to a list before iterating\n",
    "for var_name, var_value in list(variables.items()):\n",
    "    if isinstance(var_value, pd.DataFrame) and var_name != 'df_final':\n",
    "        del variables[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quarta parte da análise:\n",
    "- Teste\n",
    "\n",
    "###### nesta quarta parte da análise é possível verificar que:\n",
    "O valor de p é 0,185 ou 18,5%. Um valor de p menor que 0,05 geralmente é considerado evidência forte o suficiente para rejeitar a hipótese nula e aceitar a hipótese alternativa.\n",
    "\n",
    "- H0 (Hipótese nula): O teste não rejeita a hipótese nula pois não há associação significativa entre \"Grupo\" e \"Comprou\". Em outras palavras, a taxa de compra é praticamente a mesma para os grupos 'CONTROLE' e 'TESTE'.\n",
    "\n",
    "- H1 (Hipótese alternativa): O Teste rejeita hipótese alternativa que seria uma associação significativa entre \"Grupo\" e \"Comprou\".\n",
    "\n",
    "Portanto não houve diferença significativa entre o Modelo ANTIGO e NOVO de disparo de e-mails.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:37.996773Z",
     "iopub.status.busy": "2024-03-08T01:02:37.996773Z",
     "iopub.status.idle": "2024-03-08T01:02:38.029793Z",
     "shell.execute_reply": "2024-03-08T01:02:38.030799Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# arquivo\n",
    "wb = openpyxl.load_workbook('Exercicio_Python_CRM .xlsx', read_only=True)\n",
    "\n",
    "# aba de Cliente\n",
    "ws = wb['Cliente']\n",
    "\n",
    "# tamanho do chunk para leitura de bases grandes\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "# cabeçalho (nomes das colunas) da primeira linha\n",
    "header = [cell.value for cell in ws[1]]\n",
    "\n",
    "# dados em chunks para bases com milhões de linhas\n",
    "for i in range(2, ws.max_row, chunk_size):  # Comecça de 2 porque a primeira linha é o cabeçalho\n",
    "    rows = ws[i:i + chunk_size]\n",
    "    data = [[cell.value for cell in row] for row in rows]\n",
    "    df = pd.DataFrame(data, columns=header)  # Usando o cabeçalho como nomes das colunas\n",
    "    chunks.append(df)\n",
    "\n",
    "# Concatenando os chunks em um único DataFrame\n",
    "df_c = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Para cada coluna no DataFrame\n",
    "for col in df_c.columns:\n",
    "    # Se o tipo de dados da coluna é object (string)\n",
    "    if pd.api.types.is_object_dtype(df_c[col]):\n",
    "        # Remova os espaços em branco no início e no final\n",
    "        df_c[col] = df_c[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:38.032707Z",
     "iopub.status.busy": "2024-03-08T01:02:38.032707Z",
     "iopub.status.idle": "2024-03-08T01:02:38.063491Z",
     "shell.execute_reply": "2024-03-08T01:02:38.063995Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "# arquivo\n",
    "wb = openpyxl.load_workbook('Exercicio_Python_CRM .xlsx', read_only=True)\n",
    "\n",
    "# aba de Teste\n",
    "ws = wb['Teste']\n",
    "\n",
    "# tamanho do chunk para leitura de bases grandes\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "\n",
    "# cabeçalho (nomes das colunas) da primeira linha\n",
    "header = [cell.value for cell in ws[1]]\n",
    "\n",
    "# dados em chunks para bases com milhões de linhas\n",
    "for i in range(2, ws.max_row, chunk_size):  # Comecça de 2 porque a primeira linha é o cabeçalho\n",
    "    rows = ws[i:i + chunk_size]\n",
    "    data = [[cell.value for cell in row] for row in rows]\n",
    "    df = pd.DataFrame(data, columns=header)  # Usando o cabeçalho como nomes das colunas\n",
    "    chunks.append(df)\n",
    "\n",
    "# Concatenando os chunks em um único DataFrame\n",
    "df_tst = pd.concat(chunks, axis=0)\n",
    "\n",
    "# Para cada coluna no DataFrame\n",
    "for col in df_tst.columns:\n",
    "    # Se o tipo de dados da coluna é object (string)\n",
    "    if pd.api.types.is_object_dtype(df_tst[col]):\n",
    "        # Remova os espaços em branco no início e no final\n",
    "        df_tst[col] = df_tst[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:38.063995Z",
     "iopub.status.busy": "2024-03-08T01:02:38.063995Z",
     "iopub.status.idle": "2024-03-08T01:02:38.079848Z",
     "shell.execute_reply": "2024-03-08T01:02:38.080220Z"
    }
   },
   "outputs": [],
   "source": [
    "df_c = df_c.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:38.080220Z",
     "iopub.status.busy": "2024-03-08T01:02:38.080220Z",
     "iopub.status.idle": "2024-03-08T01:02:38.096921Z",
     "shell.execute_reply": "2024-03-08T01:02:38.096921Z"
    }
   },
   "outputs": [],
   "source": [
    "non_conforming_rows = df_tst.loc[\n",
    "    ((df_tst['Enviado'] == 0) & (df_tst['Aberto'] != 0)) |\n",
    "    ((df_tst['Enviado'] == 0) & (df_tst['Sessao'] != 0)) |\n",
    "    ((df_tst['Recebido'] == 0) & (df_tst['Aberto'] != 0)) |\n",
    "    ((df_tst['Aberto'] == 0) & (df_tst['Sessao'] != 0))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:38.096921Z",
     "iopub.status.busy": "2024-03-08T01:02:38.096921Z",
     "iopub.status.idle": "2024-03-08T01:02:38.113554Z",
     "shell.execute_reply": "2024-03-08T01:02:38.113554Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tst = df_tst.drop(non_conforming_rows.index)\n",
    "df_merged = df_tst.merge(df_c, on='CustomerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:38.113554Z",
     "iopub.status.busy": "2024-03-08T01:02:38.113554Z",
     "iopub.status.idle": "2024-03-08T01:02:38.129908Z",
     "shell.execute_reply": "2024-03-08T01:02:38.129908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by 'Grupo' and calculate the mean of 'Comprou'\n",
    "conversion_rate = df_merged.groupby('Grupo')['Comprou'].mean()\n",
    "\n",
    "# Reset the index of the conversion_rate Series to convert it into a DataFrame\n",
    "cr = conversion_rate.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "cr.columns = ['Grupo', 'conversion_rate']\n",
    "# Group by 'Grupo' and calculate the mean of 'Aberto'\n",
    "opening_rate = df_merged.groupby('Grupo')['Aberto'].mean()\n",
    "\n",
    "o_r = opening_rate.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "o_r.columns = ['Grupo', 'opening_rate']\n",
    "#o_r\n",
    "# Assuming o_r is a DataFrame with a 'Grupo' column\n",
    "merged_df = cr.merge(o_r, on='Grupo')\n",
    "merged_df['conversion_rate'] = ((merged_df['conversion_rate'] * 100).round(2)).astype(str) + '%'\n",
    "merged_df['opening_rate'] = ((merged_df['opening_rate'] * 100).round(2)).astype(str) + '%'\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T01:02:38.132913Z",
     "iopub.status.busy": "2024-03-08T01:02:38.132913Z",
     "iopub.status.idle": "2024-03-08T01:02:38.413867Z",
     "shell.execute_reply": "2024-03-08T01:02:38.413867Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# Criando a tabela de contingência\n",
    "tabela_contingencia = pd.crosstab(df_merged['Grupo'], df_merged['Comprou'])\n",
    "\n",
    "# Realizando o teste\n",
    "chi2, p, df, expected = stats.chi2_contingency(tabela_contingencia)\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(\"Valor de p:\", p)\n",
    "\n",
    "# Se p < 0.05, há significância estatística\n",
    "if p < 0.05:\n",
    "    print(\"Existe relação significativa entre Grupo e Comprou\")\n",
    "else:\n",
    "    print(\"Não há relação significativa entre Grupo e Comprou\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Próximos Passos\n",
    "\n",
    "- testar a capacidade dos dados em identificar tendências, sazonalidade e predições utlizando o algoritmo PROPHET para a timeseries Data e dados de vendas para melhor interpretar o calendário e seus momentos importantes para o varejo de roupas\n",
    "- outros dados externos podem auxiliar nos modelos (Bureau de Dados, IBGE, Ministérios,...)\n",
    "- dados de concorrência\n",
    "\n",
    "##### sobre a análise\n",
    "\n",
    "- vale manter as estratégias em relação a peças vermelhas. Estão bem consolidadas nas preferências dos clientes.\n",
    "- na possibilidade de promoção de outros produtos Azul pode ser uma cor interessante\n",
    "- as estratégias de MKT precisam ser renovadas. \n",
    "    - as promoções não teem surtido efeito\n",
    "    - a NOVA estratégia de email marketing também não se mostrou significativa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('jupyter nbconvert --no-input --to html crm_v5_1.ipynb')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
